{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os.path as osp\n",
    "\n",
    "from abl.reasoning import ReasonerBase, KBBase\n",
    "from abl.learning import BasicNN, ABLModel\n",
    "from abl.bridge import SimpleBridge\n",
    "from abl.evaluation import SymbolMetric, SemanticsMetric\n",
    "from abl.utils import ABLLogger, print_log\n",
    "\n",
    "from examples.models.nn import SymbolNet\n",
    "from datasets.get_hwf import get_hwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logger and print basic information\n",
    "print_log(\"Abductive Learning on the HWF example.\", logger=\"current\")\n",
    "\n",
    "# Retrieve the directory of the Log file and define the directory for saving the model weights.\n",
    "log_dir = ABLLogger.get_current_instance().log_dir\n",
    "weights_dir = osp.join(log_dir, \"weights\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize knowledge base and reasoner\n",
    "class HWF_KB(KBBase):\n",
    "    def _valid_candidate(self, formula):\n",
    "        if len(formula) % 2 == 0:\n",
    "            return False\n",
    "        for i in range(len(formula)):\n",
    "            if i % 2 == 0 and formula[i] not in [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]:\n",
    "                return False\n",
    "            if i % 2 != 0 and formula[i] not in [\"+\", \"-\", \"times\", \"div\"]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def logic_forward(self, formula):\n",
    "        if not self._valid_candidate(formula):\n",
    "            return np.inf\n",
    "        mapping = {str(i): str(i) for i in range(1, 10)}\n",
    "        mapping.update({\"+\": \"+\", \"-\": \"-\", \"times\": \"*\", \"div\": \"/\"})\n",
    "        formula = [mapping[f] for f in formula]\n",
    "        return eval(\"\".join(formula))\n",
    "\n",
    "\n",
    "kb = HWF_KB(\n",
    "    pseudo_label_list=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"+\", \"-\", \"times\", \"div\"],\n",
    "    max_err=1e-10,\n",
    "    use_cache=False,\n",
    ")\n",
    "reasoner = ReasonerBase(kb, dist_func=\"confidence\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize necessary component for machine learning part\n",
    "cls = SymbolNet(num_classes=len(kb.pseudo_label_list), image_size=(45, 45, 1))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cls.parameters(), lr=0.001, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BasicNN\n",
    "# The function of BasicNN is to wrap NN models into the form of an sklearn estimator\n",
    "base_model = BasicNN(\n",
    "    model=cls,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    save_interval=1,\n",
    "    save_dir=weights_dir,\n",
    "    batch_size=128,\n",
    "    num_epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ABL model\n",
    "# The main function of the ABL model is to serialize data and\n",
    "# provide a unified interface for different machine learning models\n",
    "model = ABLModel(base_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metric\n",
    "metric_list = [SymbolMetric(prefix=\"hwf\"), SemanticsMetric(kb=kb, prefix=\"hwf\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing data\n",
    "train_data = get_hwf(train=True, get_gt_pseudo_label=True)\n",
    "test_data = get_hwf(train=False, get_gt_pseudo_label=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bridge Machine Learning and Logic Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge = SimpleBridge(model=model, reasoner=reasoner, metric_list=metric_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge.train(train_data, loops=3, segment_size=1000, save_interval=1, save_dir=weights_dir)\n",
    "bridge.test(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb6f4ceeabb9a733f366948eb80109f83aedf798cc984df1e68fb411adb27d58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
