{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from abl.bridge import SimpleBridge\n",
    "from abl.evaluation import ReasoningMetric, SymbolMetric\n",
    "from abl.learning import ABLModel, BasicNN\n",
    "from abl.reasoning import KBBase, Reasoner\n",
    "from abl.utils import ABLLogger, print_log\n",
    "from examples.mnist_add.datasets import get_mnist_add\n",
    "from examples.models.nn import LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build logger\n",
    "print_log(\"Abductive Learning on the MNIST Addition example.\", logger=\"current\")\n",
    "\n",
    "# Retrieve the directory of the Log file and define the directory for saving the model weights.\n",
    "log_dir = ABLLogger.get_current_instance().log_dir\n",
    "weights_dir = osp.join(log_dir, \"weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing data\n",
    "train_data = get_mnist_add(train=True, get_pseudo_label=True)\n",
    "test_data = get_mnist_add(train=False, get_pseudo_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(train_data[0])} data examples in the training set and {len(test_data[0])} data examples in the test set\")\n",
    "print(f\"Each of the data example has {len(train_data)} components: X, gt_pseudo_label, and Y.\")\n",
    "print(\"For instance, in the First data example in the training set, we have:\")\n",
    "print(f\"X ({len(train_data[0][0])} images):\")\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis('off') \n",
    "plt.imshow(train_data[0][0][0].numpy().transpose(1, 2, 0))\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis('off') \n",
    "plt.imshow(train_data[0][0][1].numpy().transpose(1, 2, 0))\n",
    "plt.show()\n",
    "print(f\"gt_pseudo_label ({len(train_data[1][0])} ground truth pseudo label): {train_data[1][0][0]}, {train_data[1][0][1]}\")\n",
    "print(f\"Y (their sum result): {train_data[2][0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build necessary components for BasicNN\n",
    "cls = LeNet5(num_classes=10)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cls.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build BasicNN\n",
    "# The function of BasicNN is to wrap NN models into the form of an sklearn estimator\n",
    "base_model = BasicNN(\n",
    "    cls,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    batch_size=32,\n",
    "    num_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ABLModel\n",
    "# The main function of the ABL model is to serialize data and\n",
    "# provide a unified interface for different machine learning models\n",
    "model = ABLModel(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build knowledge base and reasoner\n",
    "class AddKB(KBBase):\n",
    "    def __init__(self, pseudo_label_list):\n",
    "        super().__init__(pseudo_label_list)\n",
    "\n",
    "    # Implement the deduction function\n",
    "    def logic_forward(self, nums):\n",
    "        return sum(nums)\n",
    "\n",
    "\n",
    "kb = AddKB(pseudo_label_list=list(range(10)))\n",
    "reasoner = Reasoner(kb, dist_func=\"confidence\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up metrics\n",
    "metric_list = [SymbolMetric(prefix=\"mnist_add\"), ReasoningMetric(kb=kb, prefix=\"mnist_add\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bridge Machine Learning and Logic Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge = SimpleBridge(model, reasoner, metric_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge.train(train_data, loops=5, segment_size=1/3, save_interval=1, save_dir=weights_dir)\n",
    "bridge.test(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c8d454494e49869a4ee4046edcac9a39ff683f7d38abf0769f648402670238e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
