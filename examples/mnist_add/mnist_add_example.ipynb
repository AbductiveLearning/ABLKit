{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from abl.reasoning import ReasonerBase, KBBase\n",
    "\n",
    "from abl.learning import BasicNN, ABLModel\n",
    "from abl.bridge import SimpleBridge\n",
    "from abl.evaluation import SymbolMetric\n",
    "from abl.utils import ABLLogger, print_log\n",
    "\n",
    "from examples.models.nn import LeNet5\n",
    "from examples.mnist_add.datasets.get_mnist_add import get_mnist_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/15 21:35:55 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Abductive Learning on the MNIST Add example.\n"
     ]
    }
   ],
   "source": [
    "# Initialize logger\n",
    "print_log(\"Abductive Learning on the MNIST Add example.\", logger=\"current\")\n",
    "\n",
    "# Retrieve the directory of the Log file and define the directory for saving the model weights.\n",
    "log_dir = ABLLogger.get_current_instance().log_dir\n",
    "weights_dir = osp.join(log_dir, \"weights\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize knowledge base and abducer\n",
    "class add_KB(KBBase):\n",
    "    def logic_forward(self, nums):\n",
    "        return sum(nums)\n",
    "\n",
    "kb = add_KB(pseudo_label_list=list(range(10)))\n",
    "\n",
    "# kb = prolog_KB(pseudo_label_list=list(range(10)), pl_file='datasets/mnist_add/add.pl')\n",
    "abducer = ReasonerBase(kb, dist_func=\"confidence\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize necessary component for machine learning part\n",
    "cls = LeNet5(num_classes=len(kb.pseudo_label_list))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cls.parameters(), lr=0.001, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BasicNN\n",
    "# The function of BasicNN is to wrap NN models into the form of an sklearn estimator\n",
    "base_model = BasicNN(\n",
    "    cls,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    batch_size=32,\n",
    "    num_epochs=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ABL model to join two parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ABL model\n",
    "# The main function of the ABL model is to serialize data and \n",
    "# provide a unified interface for different machine learning models\n",
    "model = ABLModel(base_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metric\n",
    "metric = [SymbolMetric(prefix=\"mnist_add\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing data\n",
    "train_data = get_mnist_add(train=True, get_pseudo_label=True)\n",
    "test_data = get_mnist_add(train=False, get_pseudo_label=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bridge Machine Learning and Logic Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge = SimpleBridge(model, abducer, metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/15 21:36:18 - abl - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Transform used in the training phase will be used in prediction.\n",
      "11/15 21:36:21 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [1/5] segment(train) [1/3] model loss is 1.80390\n",
      "11/15 21:36:24 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [1/5] segment(train) [2/3] model loss is 1.41898\n",
      "11/15 21:36:26 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [1/5] segment(train) [3/3] model loss is 1.08221\n",
      "11/15 21:36:26 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluation start: loop(val) [1]\n",
      "11/15 21:36:27 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluation ended, mnist_add/character_accuracy: 0.590 \n",
      "11/15 21:36:27 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Saving model: loop(save) [1]\n",
      "11/15 21:36:27 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Checkpoints will be saved to results/20231115_21_35_55/weights/model_checkpoint_loop_1.pth\n",
      "11/15 21:36:29 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [2/5] segment(train) [1/3] model loss is 0.65210\n",
      "11/15 21:36:31 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [2/5] segment(train) [2/3] model loss is 0.13546\n",
      "11/15 21:36:32 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [2/5] segment(train) [3/3] model loss is 0.08060\n",
      "11/15 21:36:32 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluation start: loop(val) [2]\n",
      "11/15 21:36:34 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluation ended, mnist_add/character_accuracy: 0.982 \n",
      "11/15 21:36:34 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Saving model: loop(save) [2]\n",
      "11/15 21:36:34 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Checkpoints will be saved to results/20231115_21_35_55/weights/model_checkpoint_loop_2.pth\n",
      "11/15 21:36:35 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [3/5] segment(train) [1/3] model loss is 0.06446\n",
      "11/15 21:36:37 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [3/5] segment(train) [2/3] model loss is 0.05224\n",
      "11/15 21:36:39 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [3/5] segment(train) [3/3] model loss is 0.05119\n",
      "11/15 21:36:39 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluation start: loop(val) [3]\n",
      "11/15 21:36:40 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluation ended, mnist_add/character_accuracy: 0.989 \n",
      "11/15 21:36:40 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Saving model: loop(save) [3]\n",
      "11/15 21:36:40 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Checkpoints will be saved to results/20231115_21_35_55/weights/model_checkpoint_loop_3.pth\n",
      "11/15 21:36:42 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [4/5] segment(train) [1/3] model loss is 0.04667\n",
      "11/15 21:36:44 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [4/5] segment(train) [2/3] model loss is 0.04027\n",
      "11/15 21:36:45 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [4/5] segment(train) [3/3] model loss is 0.03672\n",
      "11/15 21:36:45 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluation start: loop(val) [4]\n",
      "11/15 21:36:46 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluation ended, mnist_add/character_accuracy: 0.990 \n",
      "11/15 21:36:46 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Saving model: loop(save) [4]\n",
      "11/15 21:36:46 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Checkpoints will be saved to results/20231115_21_35_55/weights/model_checkpoint_loop_4.pth\n",
      "11/15 21:36:48 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [5/5] segment(train) [1/3] model loss is 0.03381\n",
      "11/15 21:36:50 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [5/5] segment(train) [2/3] model loss is 0.03333\n",
      "11/15 21:36:52 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - loop(train) [5/5] segment(train) [3/3] model loss is 0.03195\n",
      "11/15 21:36:52 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluation start: loop(val) [5]\n",
      "11/15 21:36:53 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluation ended, mnist_add/character_accuracy: 0.992 \n",
      "11/15 21:36:53 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Saving model: loop(save) [5]\n",
      "11/15 21:36:53 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Checkpoints will be saved to results/20231115_21_35_55/weights/model_checkpoint_loop_5.pth\n",
      "11/15 21:36:53 - abl - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluation ended, mnist_add/character_accuracy: 0.988 \n"
     ]
    }
   ],
   "source": [
    "bridge.train(train_data, loops=5, segment_size=10000, save_interval=1, save_dir=weights_dir)\n",
    "bridge.test(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c8d454494e49869a4ee4046edcac9a39ff683f7d38abf0769f648402670238e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
